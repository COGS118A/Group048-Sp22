{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/H-arshit/UNET-On-COCO/blob/master/tf_Keras_COCO_UNET.ipynb\n",
    "# Importing Data From COCO\n",
    "\n",
    "from pycocotools import coco, cocoeval, _mask\n",
    "from pycocotools import mask as maskUtils \n",
    "import array\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_DIR = 'coco-2017'\n",
    "TRAIN_IMG = COCO_DIR + '/train/data'\n",
    "VAL_IMG = COCO_DIR + '/validation/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_NAMES=['person']\n",
    "\n",
    "ANNOTATION_FILE_VAL = 'coco-2017/raw/instances_val2017.json'\n",
    "ANNOTATION_FILE_TRAIN = 'coco-2017/raw/instances_train2017.json'\n",
    "\n",
    "\n",
    "coco_train = coco.COCO(ANNOTATION_FILE_TRAIN)\n",
    "catIds_train = coco_train.getCatIds(catNms=CATEGORY_NAMES);\n",
    "imgIds_train = coco_train.getImgIds(catIds=catIds_train);\n",
    "imgDict_train = coco_train.loadImgs(imgIds_train)\n",
    "len(imgIds_train) , len(catIds_train)\n",
    "\n",
    "\n",
    "coco_val = coco.COCO(ANNOTATION_FILE_VAL)\n",
    "catIds_val = coco_val.getCatIds(catNms=CATEGORY_NAMES);\n",
    "imgIds_val = coco_val.getImgIds(catIds=catIds_val);\n",
    "imgDict_val = coco_val.loadImgs(imgIds_val)\n",
    "len(imgIds_val) , len(catIds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a465c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(imgIds_train)\n",
    "shuffle(imgIds_val)\n",
    "\n",
    "imgIds_train = imgIds_train[0:6000]\n",
    "imgIds_val = imgIds_val[0:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_person = [\"{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
    "del_img_train = set(os.listdir(\"coco-2017/train/data\")) - set(train_images_person)\n",
    "for file_name in del_img_train:\n",
    "    file_name = \"coco-2017/train/data/\" + file_name\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb68898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"coco-2017/train/data\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_person = [\"{0:012d}.jpg\".format(ids) for ids in imgIds_val]\n",
    "del_img_val = set(os.listdir(VAL_IMG)) - set(val_images_person)\n",
    "i = 1\n",
    "for file_name in del_img_val:\n",
    "    file_name = VAL_IMG + \"/\" + file_name\n",
    "    if os.path.exists(file_name):\n",
    "        print(i)\n",
    "        os.remove(file_name)\n",
    "        i+=1\n",
    "\n",
    "len(os.listdir(VAL_IMG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cd172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37392026",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mask_train_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "\n",
    "for ID in imgIds_train:\n",
    "\n",
    "    file_path = \"./mask_train_2017/COCO_train2017_{0:012d}.jpg\".format(ID)\n",
    "  \n",
    "    sampleImgIds = coco_train.getImgIds(imgIds = [ID])\n",
    "    sampleImgDict = coco_train.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
    "\n",
    "    annIds = coco_train.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_train, iscrowd=0)\n",
    "    anns = coco_train.loadAnns(annIds)\n",
    "\n",
    "\n",
    "    mask = coco_train.annToMask(anns[0])\n",
    "    for i in range(len(anns)):\n",
    "        mask = mask | coco_train.annToMask(anns[i])\n",
    "  \n",
    "    mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
    "    mask.save(file_path)\n",
    "    count = count + 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mask_val_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for ID in imgIds_val:\n",
    "\n",
    "    file_path = \"./mask_val_2017/COCO_val2017_{0:012d}.jpg\".format(ID)\n",
    "  \n",
    "    sampleImgIds = coco_val.getImgIds(imgIds = [ID])\n",
    "    sampleImgDict = coco_val.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
    "\n",
    "    annIds = coco_val.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_val, iscrowd=0)\n",
    "    anns = coco_val.loadAnns(annIds)\n",
    "\n",
    "\n",
    "    mask = coco_val.annToMask(anns[0])\n",
    "    for i in range(len(anns)):\n",
    "        mask = mask | coco_val.annToMask(anns[i])\n",
    "  \n",
    "    mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
    "    mask.save(file_path)\n",
    "  \n",
    "    count = count + 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17f530",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "\n",
    "seed = 0\n",
    "\n",
    "random.seed = seed\n",
    "np.random.seed = seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(tf.keras.utils.Sequence):\n",
    "  \n",
    "    def __init__(self , path_input , path_mask , batch_size = 8 , image_size = 128 , split='train'):\n",
    "    \n",
    "        self.ids = os.listdir(path_input)\n",
    "        self.path_input = path_input\n",
    "        self.path_mask = path_mask\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "        self.split = split\n",
    "  \n",
    "    def __load__(self , id_name):\n",
    "    \n",
    "        image_path = os.path.join(self.path_input , id_name)\n",
    "        mask_path = os.path.join(self.path_mask , \"COCO_{}2017_{}\".format(self.split, id_name)) \n",
    "    \n",
    "        image = cv2.imread(image_path , 1) # 1 specifies RGB format\n",
    "        image = cv2.resize(image , (self.image_size , self.image_size)) # resizing before inserting to the network\n",
    "    \n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.resize(mask , (self.image_size , self.image_size))\n",
    "        mask = mask[:, :, 0].reshape((self.image_size , self.image_size , 1))\n",
    "      \n",
    "        #normalize image\n",
    "        image = image / 255.0\n",
    "        mask = mask / 255.0\n",
    "    \n",
    "        return image , mask\n",
    "  \n",
    "    def __getitem__(self , index):\n",
    "    \n",
    "        if (index + 1)*self.batch_size > len(self.ids):\n",
    "            self.batch_size = len(self.ids) - index * self.batch_size\n",
    "        \n",
    "        file_batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "    \n",
    "        images = []\n",
    "        masks = []\n",
    "    \n",
    "        for id_name in file_batch : \n",
    "      \n",
    "            _img , _mask = self.__load__(id_name)\n",
    "            print(_img.shape)\n",
    "            images.append(_img)\n",
    "            masks.append(_mask)\n",
    "    \n",
    "    \n",
    "        images = np.array(images)\n",
    "        masks = np.array(masks)\n",
    "    \n",
    "    \n",
    "        return images , masks\n",
    "  \n",
    "  \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "  \n",
    "  \n",
    "    def __len__(self):\n",
    "    \n",
    "        return int(np.ceil(len(self.ids) / float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d3861",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ccade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(\n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    max_pool_window=(2, 2),\n",
    "    max_pool_stride=(2, 2)\n",
    "):\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    # conv for skip connection\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    pool = MaxPooling2D(pool_size=max_pool_window, strides=max_pool_stride)(conv)\n",
    "\n",
    "    return conv, pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottle_neck(\n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"\n",
    "):\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(    \n",
    "    input_tensor,\n",
    "    no_filters,\n",
    "    skip_connection, \n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    upsampling_factor = (2,2),\n",
    "    max_pool_window = (2,2),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"):\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters = no_filters,\n",
    "        kernel_size= max_pool_window,\n",
    "        strides = strides,\n",
    "        activation = None,\n",
    "        padding = padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(UpSampling2D(size = upsampling_factor)(input_tensor))\n",
    "    \n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv) \n",
    "    \n",
    "    \n",
    "    conv = concatenate( [skip_connection , conv]  , axis = -1)\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = Conv2D(\n",
    "        filters=no_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        activation=None,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "\n",
    "    conv = BatchNormalization(scale=True)(conv)\n",
    "\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_block(input_tensor,\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\"\n",
    "):\n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=2,\n",
    "        kernel_size=(3,3),\n",
    "        strides=(1,1),\n",
    "        activation=\"relu\",\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_tensor)\n",
    "    \n",
    "    \n",
    "    conv = Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=(1,1),\n",
    "        strides=(1,1),\n",
    "        activation=\"sigmoid\",\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(conv)\n",
    "    \n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(input_shape = (128,128,3)):\n",
    "    \n",
    "    filter_size = [64,128,256,512,1024]\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    \n",
    "    d1 , p1 = down_block(input_tensor= inputs,\n",
    "                         no_filters=filter_size[0],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    d2 , p2 = down_block(input_tensor= p1,\n",
    "                         no_filters=filter_size[1],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    d3 , p3 = down_block(input_tensor= p2,\n",
    "                         no_filters=filter_size[2],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    d4 , p4 = down_block(input_tensor= p3,\n",
    "                         no_filters=filter_size[3],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\",\n",
    "                         max_pool_window=(2,2),\n",
    "                         max_pool_stride=(2,2))\n",
    "    \n",
    "    \n",
    "    b = bottle_neck(input_tensor= p4,\n",
    "                         no_filters=filter_size[4],\n",
    "                         kernel_size = (3,3),\n",
    "                         strides=(1,1),\n",
    "                         padding=\"same\",\n",
    "                         kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    u4 = up_block(input_tensor = b,\n",
    "                  no_filters = filter_size[3],\n",
    "                  skip_connection = d4,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    u3 = up_block(input_tensor = u4,\n",
    "                  no_filters = filter_size[2],\n",
    "                  skip_connection = d3,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    u2 = up_block(input_tensor = u3,\n",
    "                  no_filters = filter_size[1],\n",
    "                  skip_connection = d2,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    u1 = up_block(input_tensor = u2,\n",
    "                  no_filters = filter_size[0],\n",
    "                  skip_connection = d1,\n",
    "                  kernel_size=(3, 3),\n",
    "                  strides=(1, 1),\n",
    "                  upsampling_factor = (2,2),\n",
    "                  max_pool_window = (2,2),\n",
    "                  padding=\"same\",\n",
    "                  kernel_initializer=\"he_normal\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = output_block(input_tensor=u1 , \n",
    "                         padding = \"same\",\n",
    "                         kernel_initializer= \"he_normal\")\n",
    "    \n",
    "    model = Model(inputs = inputs , outputs = output)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d03b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(input_shape = (128,128,3))\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128 \n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362be950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGen(path_input = TRAIN_IMG , path_mask = './mask_train_2017' , batch_size = batch_size , image_size = image_size)\n",
    "val_gen = DataGen(path_input =  VAL_IMG, path_mask =  './mask_val_2017', batch_size = batch_size , image_size = image_size, split='val')\n",
    "\n",
    "\n",
    "train_steps =  len(os.listdir(TRAIN_IMG))/batch_size\n",
    "\n",
    "\n",
    "model.fit(train_gen , validation_data = val_gen , steps_per_epoch = train_steps , epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be04a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0d971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cabef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
