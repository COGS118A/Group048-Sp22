{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c0d3f7",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c736cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.coco as coco\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912ec66",
   "metadata": {},
   "source": [
    "We will use the COCO API to get read in the json files with the targets and all the annotations. It will help us work with the correspondence between the images that have unique image ids and the annotations that also have their own unique annotation ids and also contain the variable that defines the image id that the annotation corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226bafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file paths\n",
    "anot_path_train = \"instances_train2017.json\"\n",
    "anot_path_val = \"instances_val2017.json\"\n",
    "img_path_train = \"../train/data\"\n",
    "img_path_val = \"../validation/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e321399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.68s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# create the coco objects to work with the images and their annotations\n",
    "coco_train = coco.COCO(anot_path_train)\n",
    "coco_val = coco.COCO(anot_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d49839",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = coco_train.getImgIds()\n",
    "# use the same category ids from EDA\n",
    "cat_ids = [1,2,3,4,6,7,8,10,11,13,14,17,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf3044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 30,000 random images from the larger training dataset for training\n",
    "num_train_samples = 30000\n",
    "indices = np.random.choice(range(len(imgs_train)), num_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7a386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new annotation file with annotations corresponding to the categories that we need\n",
    "with open(anot_path_train, 'r') as train_file:\n",
    "    train_data = json.load(train_file)\n",
    "    new_train_data = {}\n",
    "    new_train_data['info'] = train_data['info'].copy()\n",
    "    new_train_data['categories'] = train_data['categories'].copy()\n",
    "    new_train_data['images'] = []\n",
    "    new_train_data['annotations'] = []\n",
    "    for index in indices:\n",
    "        new_train_data['images'].append(train_data['images'][index].copy())\n",
    "        img_id = imgs_train[index]\n",
    "        ann_ids = coco_train.getAnnIds([img_id])\n",
    "        annotations = coco_train.loadAnns(ann_ids)\n",
    "        for ann in annotations:\n",
    "            if ann['category_id'] in cat_ids:\n",
    "                new_train_data['annotations'].append(ann.copy())\n",
    "train_file.close()\n",
    "\n",
    "with open('sub_samples_instances_train2017.json', 'w') as file:\n",
    "    json.dump(new_train_data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e154a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_val = coco_val.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65730adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 5,000 random images from the larger validation dataset for validation\n",
    "num_val_samples = 5000\n",
    "indices = np.random.choice(range(len(imgs_val)), num_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9799817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new annotation file with annotations corresponding to the categories that we need\n",
    "with open(anot_path_val, 'r') as val_file:\n",
    "    val_data = json.load(val_file)\n",
    "    new_val_data = {}\n",
    "    new_val_data['info'] = val_data['info'].copy()\n",
    "    new_val_data['categories'] = val_data['categories'].copy()\n",
    "    new_val_data['images'] = []\n",
    "    new_val_data['annotations'] = []\n",
    "    for index in indices:\n",
    "        new_val_data['images'].append(val_data['images'][index].copy())\n",
    "        img_id = imgs_val[index]\n",
    "        ann_ids = coco_val.getAnnIds([img_id])\n",
    "        annotations = coco_val.loadAnns(ann_ids)\n",
    "        for ann in annotations:\n",
    "            if ann['category_id'] in cat_ids:\n",
    "                new_val_data['annotations'].append(ann.copy())\n",
    "val_file.close()\n",
    "\n",
    "with open('sub_samples_instances_val2017.json', 'w') as file:\n",
    "    json.dump(new_val_data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf3f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
